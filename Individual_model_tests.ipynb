{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "\n",
    "from my_modules.model_learning.model_phases import train_epoch, valid_epoch, test_model\n",
    "from my_modules.nsclc.nsclc_dataset import NSCLCDataset\n",
    "from my_modules.model_learning import loader_maker"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# NSCLC Dataset\n",
    "`NSCLCDataset(self, root, mode, xl_file=None, label=None)`\n",
    "\n",
    "`NSCLCDataset` is a custom dataset class of images from intensity- and lifetime- based MPM imaging from the `root` \n",
    "positional argument and associated labels as read from the `.xlsx` file at `xl_file` or found in the `root` if `xl_file`\n",
    "is not input. Images have been externally preprocessed to provide traditional endpoints of imaging, namely:\n",
    "* $ORR = \\frac{I_{FAD}}{I_{FAD}+I_{NAD(P)H}}$\n",
    "* FLIM photon counts\n",
    "* Phasor coordinates (real and imaginary components of Fourier Transform, $G$ & $S$)\n",
    "* Bi-exponential Fit parameters:\n",
    "  - $\\alpha_1$\n",
    "  - $\\alpha_2$\n",
    "  - $\\tau_1$\n",
    "  - $\\tau_2$\n",
    "If called, the bound fraction ($\\alpha_2\\% = \\frac{\\alpha_2}{\\alpha_1+\\alpha_2}$) \n",
    "and mean lifetime ($\\tau_m = \\alpha_1\\%\\tau_1 + \\alpha_2\\%\\tau_2$) will be calculated internally.\n",
    "\n",
    "Either at the time of the call using the keyword argument `label=YOUR_LABEL_CHOICE` or post-hoc by setting the attribute\n",
    "`label`, an `NSCLCDataset` must have label set, otherwise it will raise an error when an item is retrieved. \n",
    "Available labels and their set-names (case-insensitive) are:\n",
    "* Treatment response:  `'Response'` or `'R'`\n",
    "* Metastatic assessment: `'Metastases'` or `'Mets'` or `'M'`\n",
    "* Image masks: `'mask'`\n",
    "\n",
    "When created, an `NSCLCDataset` will stack each desired endpoint (defined at the time of the call as positional argument\n",
    "`modes`, or set as the attribute `modes`) into a 3D image stack of size $\\left(C, H, W\\right)$ where $C$ is the called\n",
    "mode of the image, or the _channel_, ordered by the call order. Images are not held in memory, but loaded when \n",
    "`__getitem__` is called (usually indexing). By default, $ORR$, $G$, $S$, Photon counts, $\\tau_m$, and $\\alpha_2\\%$ are\n",
    "returned, in that order. This same stack can also be returned by calling `NSCLCDataset` with the mode argument of \n",
    "`['all']`. \n",
    "\n",
    "`NSCLCDataset` also provides further processing abilities including the following:\n",
    "* `normalize_channels_to_max()` finds the max value for each channel of the stack and scales each channel to the max, \n",
    "such that no value will exceed 1. After calculation, the scaling values are stored as an attribute `scalars`. \n",
    "Normalization can be toggled quickly by setting the attribute `normalized` to `True` or `False` directly. This \n",
    "circumvents any need to recalculate `scalars` each time. \n",
    "* `dist_transform()` converts each channel of the image stack into a histogram. In order for the histogram to be \n",
    "meaningful across samples, normalization is automatically applied. This can be overwritten by resetting the `normalized`\n",
    "attribute to `False` after calling `dist_transform`. The histograms are all normalized as PDFs, to \n",
    "prevent gradient explosions in training.\n",
    "* `augment()` provides default data-augmentation behavior using `torchvision.transforms.FiveCrop()` set to crop the full\n",
    "image into four corner and a center sub-image. Augmentation is applicable to both image and histogram datasets, as \n",
    "FiveCrop guarantees all images are distinct in distribution as well (in contrast to TenCrop).\n",
    "\n",
    "Beyond processing, `NSCLCDataset` has a built-in method `show_random()` method that will randomly visualize 5 samples \n",
    "from the set along with the labels. Attribute `name` which will automatically update to reflect all the specific dataset\n",
    "features (e.g. modes, augmentation). Attribute `shape` will return the shape of the data directly (without the label). "
   ],
   "id": "a0e6ceba4d49544"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "data = NSCLCDataset('E:\\\\NSCLC Data - PMD', ['orr', 'photons', 'taumean', 'boundfraction'], label='Response')",
   "id": "22065da087446b19",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data.normalize_channels_to_max()\n",
    "data.show_random()"
   ],
   "id": "e165798fbd8ec9a6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Set hyperparameters\n",
    "# Prepare training/data-loading parameters\n",
    "optim_fun = optim.Adam\n",
    "criterion = nn.BCELoss()\n",
    "bs = 32  # Batch size\n",
    "kf = 5  # Number of folds for cross validation\n",
    "\n",
    "# Iterable hyperparameters\n",
    "hyperparameters = {'Raw': {'Fast': {'LR': 0.01, 'EP': 125},\n",
    "                       'Mid': {'LR': 0.001, 'EP': 500},\n",
    "                       'Slow': {'LR': 0.00001, 'EP': 2500}},\n",
    "               'Augmented': {'Fast': {'LR': 0.01, 'EP': 125},\n",
    "                             'Mid': {'LR': 0.001, 'EP': 500},\n",
    "                             'Slow': {'LR': 0.00001, 'EP': 2500}}}\n",
    "\n",
    "status = ['Response', 'Metastases']\n",
    "\n",
    "results = {'Image': {'Single': {}, 'KFold': {}},\n",
    "           'Hist': {'Single': {}, 'KFold': {}}}"
   ],
   "id": "37d759489a0e57e5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Create dataloaders using defaults\n",
    "train_loader, eval_loader, test_loader = loader_maker(data)"
   ],
   "id": "64d1de3478e12aec",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Import, train, test model\n",
    "from my_modules.custom_models.classifier_models import RegularizedParallelCNNet\n",
    "\n",
    "# Set up training style manually\n",
    "data_aug = 'Raw'\n",
    "train_rate = 'Fast'\n",
    "ep = hyperparameters[data_aug][train_rate]['EP']\n",
    "lr = hyperparameters[data_aug][train_rate]['LR']\n",
    "label = status[0]\n",
    "model = RegularizedParallelCNNet(data.shape)\n",
    "optimizer = optim_fun(model.parameters(), lr=lr)\n",
    "\n",
    "# Save path for best-performer in validation\n",
    "model_path = f'./{model.name}_Epochs-{ep}_{data.name}.pth'\n",
    "\n",
    "# Train\n",
    "train_loss = []\n",
    "eval_loss = []\n",
    "eval_accu = []\n",
    "for epoch in range(ep):\n",
    "    print(f'>>>{model.name} Epoch {epoch+1}/{ep}...')\n",
    "    epoch_loss = train_epoch(model, train_loader, criterion, optimizer)\n",
    "    train_loss.append(epoch_loss)\n",
    "    \n",
    "    vali_loss, vali_accu = valid_epoch(model, eval_loader, criterion)\n",
    "    eval_loss.append(vali_loss)\n",
    "    eval_accu.append(vali_accu)\n",
    "    print(f'>>>Train Loss: {epoch_loss} >>> Eval Loss: {vali_loss}. Accu: {vali_accu}.')\n",
    "\n",
    "    # Save best performing model\n",
    "    if epoch == 0:\n",
    "        best_acc = eval_accu[-1]\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "    elif eval_accu[-1] > best_acc:\n",
    "        torch.save(model.state_dict(), model_path)\n",
    "        best_acc = eval_accu[-1]\n",
    "    \n",
    "# Test\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "correct = test_model(model, test_loader)\n",
    "accu = correct / len(test_loader.dataset)\n",
    "\n",
    "print(f'|--Testing Accuracy: {accu}--|')"
   ],
   "id": "c278f99b7a6c6dd9",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
